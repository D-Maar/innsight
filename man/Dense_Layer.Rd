% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Layers.R
\name{Dense_Layer}
\alias{Dense_Layer}
\title{Dense layer of a Neural Network}
\description{
Implementation of a regular densely-connected Neural Network layer as an R6 class,
where input, preactivation and output values of the last forward pass are stored
(same for a reference input, if this is needed). Applies
a linear transformation followed by an activation function \eqn{\sigma} to the incoming
data, i.e.
\deqn{y = \sigma (W^T x + b).}
}
\examples{
# Weight matrix of shape (number input features x number outputs)
# for example (3,5)
W <- matrix(c(1, -1, 2, 4, -1,
              2, -5, 3, 1, -2,
              3, 4, -1, -2, 4), nrow = 3, ncol = 5, byrow = TRUE)
# Bias vector of length (number outputs)
b <- c(-2, 1, 3, 4, -5)
# Activation function
sigmoid <- function(x) 1 / (1 + exp(-x))
# Create a new dense layer
my_layer <- Dense_Layer$new(weights = W, bias = b, activation = sigmoid)

# example forward pass of a batch of size 4 with no reference input
inputs <- matrix(rnorm(12), ncol = 3, nrow = 4)
my_layer$forward(x = inputs)

# get preactivation of the last forward pass
my_layer$preactivation

}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{type}}{Type of the layer (in this case \code{"Dense"}).}

\item{\code{dim}}{Dimension of this layer, i.e. \emph{(dim_in, dim_out)}.}

\item{\code{weights}}{The weight matrix \eqn{W} of the dense layer with size
\emph{(dim_in, dim_out)}.}

\item{\code{bias}}{Bias vector \eqn{b} of the linear transformation. It's a vector of
length \emph{dim_out}.}

\item{\code{activation}}{Activation function \eqn{\sigma} to turn the linear
transformation into a non-linear one.}

\item{\code{activation_name}}{Name of the activation function \eqn{\sigma}.}

\item{\code{inputs}}{Save the inputs from the last forward pass of this layer.
If there was no call of method \code{Dense_Layer$forward} yet
then this value is \code{NULL}.}

\item{\code{preactivation}}{Save the outputs of the linear transformation from
the last forward pass of this layer. If there was no call of method
\code{Dense_Layer$forward} yet, then this value is \code{NULL}.}

\item{\code{outputs}}{Save the outputs of the whole layer from the last forward pass.
If there was no call of method \code{Dense_Layer$forward} yet,
then this value is \code{NULL}.}

\item{\code{inputs_ref}}{Save the reference inputs from the last forward pass of this layer.
If there was no call of method \code{Dense_Layer$forward} yet,
then this value is \code{NULL}.}

\item{\code{preactivation_ref}}{Save the reference outputs of the linear transformation from
the last forward pass of this layer. If there was no call of method
\code{Dense_Layer$forward} yet, then this value is \code{NULL}.}

\item{\code{outputs_ref}}{Save the reference outputs of the whole layer from the last forward pass.
If there was no call of method \code{Dense_Layer$forward} yet,
then this value is \code{NULL}.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{Dense_Layer$new()}}
\item \href{#method-forward}{\code{Dense_Layer$forward()}}
\item \href{#method-clone}{\code{Dense_Layer$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new instance of this class with given parameters of a dense layer.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Dense_Layer$new(weights, bias, activation, activation_name = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{weights}}{The weight matrix of dimension \emph{(dim_in , dim_out)} for the linear transformation.}

\item{\code{bias}}{The bias vector of length \emph{dim_out} for the linear transformation.}

\item{\code{activation}}{The activation function of the dense layer.}

\item{\code{activation_name}}{Name of the activation function.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A new instance of the R6 class \code{'Dense_Layer'} with the given parameters.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-forward"></a>}}
\if{latex}{\out{\hypertarget{method-forward}{}}}
\subsection{Method \code{forward()}}{
The forward method of the dense layer. This method calculates the linear
transformation with the following non-linearity for the input \code{x} and,
if needed, the reference value \code{x_ref}. In addition, the input x must
be a matrix of size \emph{(batch_size x dim_in)}, which enables batch-wise
evaluation. All the intermediate values are stored in the class attributes:
\code{inputs}, \code{preactivation},
\code{outputs}, \code{inputs_ref}, \code{preactivation_ref},
\code{outputs_ref}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Dense_Layer$forward(x, x_ref = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{Input matrix of size \emph{(batch_size x dim_in)} for this layer.}

\item{\code{x_ref}}{Reference input vector for this layer. It is only needed for
the DeepLift method and can otherwise be set to \code{NULL}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A list of two elements. The first one (\code{out}) is the output matrix
of this layer for the input \code{x} and the second entry (\code{out_ref})
is the output for the reference input \code{x_ref}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Dense_Layer$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
