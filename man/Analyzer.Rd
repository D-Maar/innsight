% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Analyzer.R
\name{Analyzer}
\alias{Analyzer}
\title{Analyzer of a Neural Network}
\description{
This class analyzes a passed neural network and then provides various ways
to better understand the predictions and the overall model. Implemented are
methods like \emph{Layer-wise Relevance Propagation (LRP)}, \emph{DeepLift}, and
\emph{Connection Weights}.
}
\examples{

## ------------------------------------------------
## Method `Analyzer$Connection_Weights`
## ------------------------------------------------

# neuralnet example
library(neuralnet)

# train a neural network
model_neuralnet <- neuralnet(Species ~Sepal.Length+ Sepal.Width + Petal.Length + Petal.Width, iris, linear.output = FALSE, hidden = c(5,4), act.fct = "tanh", rep = 2)

# create an analyzer for this model
analyzer = Analyzer$new(model_neuralnet)

# calculate importance score for all three classes with the
# connection weight method
analyzer$Connection_Weights()

# calculate importance only for class 1
analyzer$Connection_Weights(out_class = 1)


## ------------------------------------------------
## Method `Analyzer$LRP`
## ------------------------------------------------

library(neuralnet)

# train a model
nn <- neuralnet(Species ~Sepal.Length+ Sepal.Width + Petal.Length + Petal.Width, iris, linear.output = FALSE, hidden = c(5,4), rep = 2)

# create an analyzer for this model
analyzer = Analyzer$new(nn)

# get one example from the dataset as vector
input <- as.vector(t(iris[1,-5]))

# calculate relevance scores for class 2
analyzer$LRP(input, out_class = 2)

# calculate relevance scores for all classes
analyzer$LRP(input)

# calculate relevance scores for all classes with eps-rule
analyzer$LRP(input, rule_name = "eps")


## ------------------------------------------------
## Method `Analyzer$DeepLift`
## ------------------------------------------------

library(neuralnet)

# train a model
nn <- neuralnet(Species ~Sepal.Length+ Sepal.Width + Petal.Length + Petal.Width, iris, linear.output = FALSE, hidden = c(5,4), rep = 2)

# create an analyzer for this model
analyzer = Analyzer$new(nn)

# get one example from the dataset as vector
input <- as.vector(t(iris[1,-5]))
input_ref <- rnorm(4)

# calculate contribution scores for class 2
analyzer$DeepLift(input, input_ref, out_class = 2)

# calculate contribution scores for all classes
analyzer$DeepLift(input, input_ref)

# calculate contribution scores for all classes with reveal-cancel-rule
analyzer$DeepLift(input, input_ref, rule_name = "revealcancel")

}
\references{
J. D. Olden et al. (2004) \emph{An accurate comparison of methods for
quantifying variable importance in artificial neural networks using
simulated data.} Ecological Modelling 178, p. 389â€“397

S. Bach et al. (2015) \emph{On pixel-wise explanations for non-linear
classifier decisions by layer-wise relevance propagation.} PLoS ONE 10, p. 1-46

A. Shrikumar et al. (2017) \emph{Learning important features through
propagating activation differences.}  ICML 2017, p. 4844-4866
}
\seealso{
\code{\link{func_connection_weights}}

\code{\link{func_lrp}}, \code{\link{linear_simple_rule}},
\code{\link{linear_eps_rule}}, \code{\link{linear_ab_rule}},
\code{\link{linear_ww_rule}}

\code{\link{func_deeplift}}, \code{\link{rescale_rule}},
\code{\link{reveal_cancel_rule}}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{model}}{The given neural network. Can be a \code{keras}, \code{torch}, or
\code{neuralnet} model.}

\item{\code{layers}}{List of layers in the model. It contains only layers that
are relevant for the evaluation. For example a list of
\code{\link{Dense_Layer}}.}

\item{\code{num_layers}}{Number of all layers in \code{layers}.}

\item{\code{last_input}}{Last recorded input for the forward-pass
(default: \code{NULL}).}

\item{\code{last_input_ref}}{Last recorded reference input for the forward_pass
(default: \code{NULL}).}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{Analyzer$new()}}
\item \href{#method-forward}{\code{Analyzer$forward()}}
\item \href{#method-update}{\code{Analyzer$update()}}
\item \href{#method-Connection_Weights}{\code{Analyzer$Connection_Weights()}}
\item \href{#method-LRP}{\code{Analyzer$LRP()}}
\item \href{#method-DeepLift}{\code{Analyzer$DeepLift()}}
\item \href{#method-clone}{\code{Analyzer$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new analyzer for a given neural network.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Analyzer$new(model)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{model}}{A trained neural network for classification or regression
tasks to be interpreted. Only models from the following types or packages
are allowed: \code{\link[keras]{keras_model}},
\code{\link[keras]{keras_model_sequential}} or
\code{\link[neuralnet]{neuralnet}}}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A new instance of the R6-class 'Analyzer'.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-forward"></a>}}
\if{latex}{\out{\hypertarget{method-forward}{}}}
\subsection{Method \code{forward()}}{
The forward method of the whole model, i.e. it calculates the output
\eqn{y=f(x)} of a given input \code{x} respectively \code{x_ref}. In doing so
all intermediate values are stored in the individual layers.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Analyzer$forward(x, x_ref = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{Input of the model.}

\item{\code{x_ref}}{Reference input of the model. If this value is not needed, it
can be set to the default value \code{NULL}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A list with two vectors. The first one is the output for input
\code{x} and the second entry is the output for the
reference input \code{x_ref}.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-update"></a>}}
\if{latex}{\out{\hypertarget{method-update}{}}}
\subsection{Method \code{update()}}{
This method updates the stored intermediate values in each layer from the
list \code{layers} when the input \code{x} or reference input \code{x_ref}
has changed.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Analyzer$update(x, x_ref = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{Input of the model.}

\item{\code{x_ref}}{Reference input of the model. If this value is not needed, it
can be set to the default value \code{NULL}.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Returns the instance itself.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-Connection_Weights"></a>}}
\if{latex}{\out{\hypertarget{method-Connection_Weights}{}}}
\subsection{Method \code{Connection_Weights()}}{
This is an implementation of the \emph{Connection Weights} algorithm
investigated by Olden et al. (2004). It's a global method for
interpreting a model and therefore returns the feature importance for
each input variable as a vector. The main calculation is outsourced to the
method \code{\link{func_connection_weights}}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Analyzer$Connection_Weights(out_class = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{out_class}}{If the given model is a classification model, this
parameter can be used to determine which class the importance should be
calculated for. Use the default value \code{NULL} to return the importance
for all classes.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A vector of the length of the input features, which contains the
importance scores for each input variable.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# neuralnet example
library(neuralnet)

# train a neural network
model_neuralnet <- neuralnet(Species ~Sepal.Length+ Sepal.Width + Petal.Length + Petal.Width, iris, linear.output = FALSE, hidden = c(5,4), act.fct = "tanh", rep = 2)

# create an analyzer for this model
analyzer = Analyzer$new(model_neuralnet)

# calculate importance score for all three classes with the
# connection weight method
analyzer$Connection_Weights()

# calculate importance only for class 1
analyzer$Connection_Weights(out_class = 1)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-LRP"></a>}}
\if{latex}{\out{\hypertarget{method-LRP}{}}}
\subsection{Method \code{LRP()}}{
This is an implementation of the \emph{Layer-wise Relevance Propagation (LRP)}
algorithm introduced by Bach et al. (2015). It's a local method for
interpreting a single element of the dataset and returns the relevance for
each input feature. The main calculation is outsourced to the
method \code{\link{func_lrp}}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Analyzer$LRP(x, out_class = NULL, rule_name = "simple", rule_param = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{The input of the model to be interpreted.}

\item{\code{out_class}}{If the given model is a classification model, this
parameter can be used to determine which class the relevance should be
calculated for. Use the default value \code{NULL} to return the relevance
for all classes.}

\item{\code{rule_name}}{The name of the rule, with which the relevances are
calculated. Implemented are \code{"simple"}, \code{"eps"}, \code{"ab"},
\code{"ww"} (default: \code{"simple"}).}

\item{\code{rule_param}}{The parameter of the selected rule. Note: Only the rules
\code{"eps"} and \code{"ab"} take use of the parameter. Use the default
value \code{NULL} for the default parameters ("eps" : \eqn{0.01}, "ab" : \eqn{0.5}).}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
If \code{out_class} is \code{NULL} it returns a matrix of shape \emph{in x out},
which contains the relevance scores for each input variable to the
output predictions. Otherwise returns a vector of the relevance scores
for each input variable for the given output class.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{library(neuralnet)

# train a model
nn <- neuralnet(Species ~Sepal.Length+ Sepal.Width + Petal.Length + Petal.Width, iris, linear.output = FALSE, hidden = c(5,4), rep = 2)

# create an analyzer for this model
analyzer = Analyzer$new(nn)

# get one example from the dataset as vector
input <- as.vector(t(iris[1,-5]))

# calculate relevance scores for class 2
analyzer$LRP(input, out_class = 2)

# calculate relevance scores for all classes
analyzer$LRP(input)

# calculate relevance scores for all classes with eps-rule
analyzer$LRP(input, rule_name = "eps")

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-DeepLift"></a>}}
\if{latex}{\out{\hypertarget{method-DeepLift}{}}}
\subsection{Method \code{DeepLift()}}{
This is an implementation of the \emph{Deep Learning Important FeaTures (DeepLIFT)}
algorithm introduced by Shrikumar et al. (2017). It's a local method for
interpreting a single element concerning a reference value and
returns the contribution for each input feature to the difference-from-reference
output. The main calculation is outsourced to the
method \code{\link{func_deeplift}}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Analyzer$DeepLift(x, x_ref = NULL, rule_name = "rescale", out_class = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{The input of the model to be interpreted.}

\item{\code{x_ref}}{The reference input for the interpretation.}

\item{\code{rule_name}}{Name of the applied rule to calculate the contributions. Use one
of \code{"rescale"} and \code{"revealcancel"} (default: \code{"rescale"}).}

\item{\code{out_class}}{If the given model is a classification model, this
parameter can be used to determine which class the contributions should be
calculated for. Use the default value \code{NULL} to return the contribution
for all classes.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
If \code{out_class} is \code{NULL} it returns a matrix of shape \emph{in x out},
which contains the contribution values for each input variable to the
output predictions. Otherwise returns a vector of the contribution values
for each input variable for the given output class.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{library(neuralnet)

# train a model
nn <- neuralnet(Species ~Sepal.Length+ Sepal.Width + Petal.Length + Petal.Width, iris, linear.output = FALSE, hidden = c(5,4), rep = 2)

# create an analyzer for this model
analyzer = Analyzer$new(nn)

# get one example from the dataset as vector
input <- as.vector(t(iris[1,-5]))
input_ref <- rnorm(4)

# calculate contribution scores for class 2
analyzer$DeepLift(input, input_ref, out_class = 2)

# calculate contribution scores for all classes
analyzer$DeepLift(input, input_ref)

# calculate contribution scores for all classes with reveal-cancel-rule
analyzer$DeepLift(input, input_ref, rule_name = "revealcancel")

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{Analyzer$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
