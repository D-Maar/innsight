% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DeepLIFT.R
\name{rescale_rule}
\alias{rescale_rule}
\title{DeepLIFT: Rescale-Rule}
\usage{
rescale_rule(mult_x_plus, mult_x_minus, layer)
}
\arguments{
\item{mult_x_plus}{The multiplier from the upper positive difference-from-reference
value to the output, i.e. \eqn{m_{\Delta y^+ \Delta t}}}

\item{mult_x_minus}{The multiplier from the upper negative difference-from-reference
value to the output, i.e. \eqn{m_{\Delta y^- \Delta t}}.}

\item{layer}{The hidden layer of type \code{\link{Dense_Layer}}.}
}
\value{
Returns the multiplier from the difference-from-reference preactivation to
the output, i.e. \eqn{m_{\Delta x \Delta t}}.
}
\description{
Implementation of the \emph{Rescale Rule} introduced by Shrikumar et al. (2017)
to determine a multiplier for an activation function.
This rule defines the same multiplier for the negative and positive
contributions by the simple ratio between difference-from-reference preactivation
\eqn{\Delta x = x-x'} and difference-from-reference postactivation
\eqn{\Delta y = \sigma(x) - \sigma(x')}, i.e.
\deqn{m_{\Delta x^+ \Delta y^+} = m_{\Delta x^- \Delta y^-} = \frac{\Delta y}{\Delta x} = \frac{\sigma(x) - \sigma(x')}{x-x'}.}
Afterward the contribution \eqn{m_{\Delta x \Delta t}} is calculated and returned.
}
\references{
A. Shrikumar et al. (2017) \emph{Learning important features through
propagating activation differences.}  ICML 2017, p. 4844-4866
}
\seealso{
\code{\link{reveal_cancel_rule}}, \code{\link{func_deeplift}},
\code{\link{Analyzer}}
}
