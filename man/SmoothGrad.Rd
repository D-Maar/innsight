% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Gradien_based.R
\name{SmoothGrad}
\alias{SmoothGrad}
\title{SmoothGrad method}
\description{
SmoothGrad was introduced by D. Smilkov et al. (2017) and is an extension to
the classical \link{Gradient} method. It takes the mean of the gradients for \code{n}
perturbations of each data point, i.e. with \eqn{\epsilon ~ N(0,\sigma)}
\deqn{1/n \sum_n d f(x+ \epsilon)_j / d x_j.}
}
\references{
D. Smilkov et al. (2017) \emph{SmoothGrad: removing noise by adding noise.}
CoRR, abs/1706.03825
}
\section{Super classes}{
\code{\link[innsight:Interpreting_Method]{innsight::Interpreting_Method}} -> \code{\link[innsight:Gradient_Based]{innsight::Gradient_Based}} -> \code{SmoothGrad}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{n}}{Number of perturbations of the input data (default: \eqn{50}).}

\item{\code{noise_level}}{The standard deviation of the gaussian
perturbation, i.e. \eqn{\sigma = (max(x) - min(x)) *} \code{noise_level}.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{SmoothGrad$new()}}
\item \href{#method-clone}{\code{SmoothGrad$clone()}}
}
}
\if{html}{
\out{<details open ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="innsight" data-topic="Interpreting_Method" data-id="get_result">}\href{../../innsight/html/Interpreting_Method.html#method-get_result}{\code{innsight::Interpreting_Method$get_result()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new instance of this class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SmoothGrad$new(
  analyzer,
  data,
  channels_first = TRUE,
  dtype = "float",
  ignore_last_act = TRUE,
  times_input = TRUE,
  n = 50,
  noise_level = 0.1
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{analyzer}}{The analyzer with the stored and torch-converted model.}

\item{\code{data}}{The given data as a torch tensor to be interpreted with the
this method.}

\item{\code{channels_first}}{The format of the given data, i.e. channels on
last dimension (\code{FALSE}) or after the batch dimension (\code{TRUE}). If the
data has no channels, use the default value \code{TRUE}.}

\item{\code{dtype}}{The type of the data (either \code{'float'} or \code{'double'}).}

\item{\code{ignore_last_act}}{A boolean value to include the last
activation into all the calculations, or not. In some cases, the last activation
leads to a saturation problem.}

\item{\code{times_input}}{Multiplies the smoothed gradients with the input features. This
method is called 'SmoothGrad x Input'.}

\item{\code{n}}{Number of perturbations of the input data (default: \eqn{50}).}

\item{\code{noise_level}}{Determines the standard deviation of the gaussian
perturbation, i.e. \eqn{\sigma = (max(x) - min(x)) *} \code{noise_level}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{SmoothGrad$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
