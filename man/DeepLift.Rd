% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DeepLift.R
\name{DeepLift}
\alias{DeepLift}
\title{Deep Learning Important FeaTures (DeepLIFT) method}
\usage{
DeepLift(analyzer, data, x_ref = NULL, rule_name = "rescale", out_class = NULL)
}
\arguments{
\item{analyzer}{An instance of the R6 class \code{\link{Analyzer}}.}

\item{data}{Either a matrix or a data frame, where each row must describe an
input to the network.}

\item{x_ref}{The reference input vector for the interpretation.}

\item{rule_name}{Name of the applied rule to calculate the contributions. Use one
of \code{"rescale"} and \code{"revealcancel"}.}

\item{out_class}{If the given model is a classification model, this
parameter can be used to determine which class the contribution should be
calculated for. Use the default value \code{NULL} to return the contribution
for all classes.}
}
\value{
It returns a list of matrices of shape \emph{(in, out)},
which contains the contribution scores for each input variable to the
output predictions or single output class (if \code{out_class} is not \code{NULL})
for every input in \code{data}.
}
\description{
This is an implementation of the \emph{Deep Learning Important FeaTures (DeepLIFT)}
algorithm introduced by Shrikumar et al. (2017). It's a local method for
interpreting a single element \eqn{x} of the dataset concerning a reference value \eqn{x'}
and returns the contribution of each input feature from the difference of the
output (\eqn{y=f(x)}) and reference output (\eqn{y'=f(x')}) prediction.
The basic idea of this method is to decompose the difference-from-reference
prediction with respect to the input features, i.e.
\deqn{\Delta y = y - y'  = \sum_i C(x_i).}
Compared to \emph{Layer-wise Relevance Propagation} (see \code{\link{LRP}}) is the
DeepLIFT method exact and not an approximation, so we get real contributions
of the input features to the difference-from-reference prediction. There are
two ways to handle activation functions: \emph{Rescale-Rule} and \emph{Reveal-Cancel-Rule}.
}
\examples{
library(neuralnet)
# train a NN and create an analyzer
nn <- neuralnet(Species ~ .,
                iris, linear.output = FALSE,
                hidden = c(10,6), act.fct = "tanh", rep = 1, threshold = 0.1 )
analyzer = Analyzer$new(nn)

# calculate contributions for all classes and x_ref = 0 with rescale rule
result <- DeepLift(analyzer, iris[,-5])
plot(result)

# calculate contributions for class 1 and x_ref first datapoint with revealcancel rule
result <- DeepLift(analyzer, iris[,-5], x_ref = 1, rule_name = "revealcancel", out_class = 1)
plot(result)

# compare class 'setosa' with 'virginica'
result <- DeepLift(analyzer, iris[iris$Species == "setosa",-5],
                   x_ref = colMeans(iris[iris$Species == "virginica",-5]),
                   rule_name = "revealcancel")
plot(result)

}
\references{
A. Shrikumar et al. (2017) \emph{Learning important features through
propagating activation differences.}  ICML 2017, p. 4844-4866
}
\seealso{
\code{\link{rescale_rule}}, \code{\link{reveal_cancel_rule}},
\code{\link{Analyzer}}
}
